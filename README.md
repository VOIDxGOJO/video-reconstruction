# ğŸ¥ Jumbled Video Frame Reconstruction using Computer Vision & Deep Learning

This project reconstructs a **completely shuffled video** back into its **correct temporal order** using a combination of:

âœ” Deep Learning (ResNet-18 embeddings)  
âœ” Feature Matching (ORB keypoints)  
âœ” Optical Flow  
âœ” k-NN graph construction  
âœ” Beam Search  
âœ” 2-opt optimization  
âœ” Simulated Annealing  
âœ” Motion-flowâ€“based orientation correction  
âœ” Optional post-processing (reverse/rotate)  

This repository is designed to demonstrate strong skills in:

- Computer Vision  
- Optimization  
- Video Processing  
- Python development  
- Practical ML system design  

---

# ğŸ“Œ Project Overview

Reconstructing video from shuffled frames is a challenging problem because:

- Consecutive frames may look very similar  
- Motion may be small or large  
- Scenes may contain static or dynamic regions  
- Frames must be arranged **globally**, not just pair-wise  

This project solves the problem **robustly** by combining multiple visual cues and optimization strategies.

---

# ğŸ§  Core Algorithm Pipeline

### 1ï¸âƒ£ **Frame Extraction**
The script extracts all frames from the shuffled video into a temporary directory.

### 2ï¸âƒ£ **Frame Embedding (Appearance Similarity)**
Two methods supported:

- **ResNet-18 pretrained (recommended)** â†’ 512-dimensional embeddings  
- **HSV Histogram fallback** â†’ used if PyTorch is unavailable  

Embeddings capture semantic similarity between frames.

---

### 3ï¸âƒ£ **k-Nearest Neighbors Graph**
Using cosine similarity, each frame keeps its **top-k most similar neighbors**.  
This reduces the problem complexity from **O(NÂ²)** to **O(NÂ·k)**.

---

### 4ï¸âƒ£ **Directional + Motion Cues**

#### âœ” ORB Keypoints  
Keypoint displacements estimate **direction of movement**.

#### âœ” Optical Flow  
Quantifies **motion smoothness** between frames.

These signals help distinguish between forward/backward adjacency.

---

### 5ï¸âƒ£ **Directed Edge Cost**

For every candidate edge (i â†’ j):

Lower = more likely to be the next frame.

---

### 6ï¸âƒ£ **Global Ordering Optimization**

The ordering is solved as a **minimum-cost Hamiltonian path problem**, optimized through:

#### âœ” Spectral initialization  
Rough global ordering prediction using graph Laplacian.

#### âœ” Beam Search  
Explores only promising paths.

#### âœ” 2-Opt  
Local swap optimization used in TSP solvers.

#### âœ” Simulated Annealing  
Escapes local minima and smoothens ordering.

---

### 7ï¸âƒ£ **Automatic Orientation Detection**
Using optical-flow smoothness:

- If reversed order is smoother â†’ **auto-reverse**  
- If not â†’ keep order

This ensures final playback is always forward-moving.

---

### 8ï¸âƒ£ **Optional Video Reversal Script**
A second script allows manual final reversal:


---

# ğŸ“‚ Repository Structure

video-reconstruction/
â”‚
â”œâ”€â”€ reconstruct_optimal.py # Main reconstruction algorithm
â”œâ”€â”€ reverse_video_by_frames.py # Utility to reverse a video
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ README.md # Documentation
â”œâ”€â”€ jumbled_video.mp4 # (Input-video)

---

# âš™ï¸ Installation

## 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/VOIDxGOJO/video-reconstruction
cd video-reconstruction
```

2ï¸âƒ£ Create virtual environment (Windows)
```bash
python -m venv venv
.\venv\Scripts\Activate.ps1
```

3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

(Optional) Install PyTorch for ResNet embeddings
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

â–¶ï¸ Usage
ğŸ§© 1. Reconstruct the jumbled video
```bash
python reconstruct_optimal.py --video jumbled_video.mp4 --out reconstructed_optimal.mp4
```

ğŸ” 2. Reverse video using second script
```bash
python reverse_video_by_frames.py --input reconstructed_optimal.mp4 --out final_video.mp4
```

ğŸ§ª Example Result

Input: Completely shuffled frame order
Output: Smooth reconstructed, forward-moving video

âœ” Frames globally sorted
âœ” Motion continuity preserved
âœ” Temporal consistency restored


ğŸ§­ Why This Approach Works
This solution combines:
Deep feature similarity
Motion information
Graph-based reasoning
Global optimization
Local refinement
Automatic direction correction
Which makes it accurate across many types of videos â€” indoor, outdoor, fast/slow motion, static scenes, etc.








